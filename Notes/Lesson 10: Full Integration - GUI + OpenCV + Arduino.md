# Lesson 10: Integrating OpenCV with PySide6 and Arduino

In this lesson, we’ll build on the previous lesson (Lesson 9) where we learned how to detect hand gestures using OpenCV and MediaPipe. In **Lesson 10**, we will integrate that hand gesture detection with a GUI using PySide6 and control an LED connected to an Arduino. We will use a **webcam feed**, a **ComboBox** to switch between **Manual** and **Gesture** modes, and **PushButtons** to manually control the LED.

Here’s the complete breakdown of the code we will work with:

---

### 1. **Imports**

```python
import cv2
import serial
import mediapipe as mp
from PySide6.QtCore import Qt, QTimer
from PySide6.QtWidgets import QApplication, QMainWindow, QLabel
from PySide6 import uic
from PySide6.QtGui import QImage, QPixmap
```

- **cv2**: This is OpenCV, which is used for computer vision tasks. In this case, it captures the webcam feed.
- **serial**: This is used to communicate with the Arduino via a USB port.
- **mediapipe as mp**: This library is used to detect hand landmarks from the webcam feed, helping us recognize gestures.
- **PySide6**: This is the Python binding for Qt6, a framework for building GUI applications. We use it here to create a user interface for controlling the Arduino.
  - `QTimer`: A timer to periodically update the webcam feed.
  - `QMainWindow`, `QLabel`: These are GUI components to display the window and the webcam feed.
  - `QImage`, `QPixmap`: These are used to display the captured webcam feed in the GUI.

---

### 2. **MainWindow Class**

```python
class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
```

- The `MainWindow` class inherits from `QMainWindow`, which is the base class for creating a main window in a PySide6 application.
- The `__init__` method is the constructor that gets called when we create a new instance of the `MainWindow` class. Inside this method, we initialize the GUI, Arduino connection, and webcam feed.

---

### 3. **Setting Up the UI**

```python
self.ui = Ui_MainWindow()
self.ui.setupUi(self)
```

- We create an instance of the `Ui_MainWindow` class (which was generated by Qt Designer) and call `setupUi(self)` to set up the interface. This method automatically configures all the widgets and layouts we designed in Qt Designer.

---

### 4. **Connecting to the Arduino**

```python
self.arduino = serial.Serial(port='/dev/cu.usbserial-1140', baudrate=9600, timeout=1)
```

- Here, we initialize a serial connection to the Arduino. The port (`'/dev/cu.usbserial-1140'`) corresponds to the specific USB port your Arduino is connected to. You’ll need to check your system to ensure the port matches.
- `baudrate=9600` sets the communication speed.
- `timeout=1` ensures that if no data is received in 1 second, the program won’t hang.

---

### 5. **Setting Up OpenCV and MediaPipe**

```python
self.cap = cv2.VideoCapture(1)
self.mp_drawing = mp.solutions.drawing_utils
self.mp_hands = mp.solutions.hands
self.hands = self.mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5)
```

- **cv2.VideoCapture(1)**: This line opens the webcam (we use `1` because it's the second camera on the system, usually the default webcam is 0).
- **mediapipe**: This part sets up MediaPipe for hand detection. `drawing_utils` helps draw the landmarks, and `Hands` is the class that performs hand tracking and gesture detection.
  - `min_detection_confidence=0.7` and `min_tracking_confidence=0.5` set thresholds for detection and tracking accuracy.

---

### 6. **Setting Up the Timer**

```python
self.timer = QTimer(self)
self.timer.timeout.connect(self.update_frame)
self.timer.start(30)
```

- **QTimer** is a class that allows us to trigger a function at regular intervals.
- We connect the `timeout` signal of the timer to the `update_frame` method, which is responsible for updating the webcam feed.
- `self.timer.start(30)` makes the timer trigger every 30 milliseconds, ensuring the webcam feed is updated quickly.

---

### 7. **Signals and Slots**

```python
self.ui.comboBox_mode.currentIndexChanged.connect(self.change_mode)
self.ui.button_led_off.clicked.connect(self.turn_led_off)
self.ui.button_led_on.clicked.connect(self.turn_led_on)
```

- **ComboBox**: When the user changes the mode (Manual or Gesture), the `currentIndexChanged` signal triggers the `change_mode` method, which switches between the two modes.
- **PushButtons**: When the user clicks the "Turn LED OFF" or "Turn LED ON" buttons, the corresponding methods (`turn_led_off` and `turn_led_on`) are called to send signals to the Arduino to control the LED.

---

### 8. **Mode Switching**

```python
def change_mode(self, index):
    if index == 0:
        print("Manual Mode")
        self.manual_mode()
    else:
        print("Gesture Mode")
        self.gesture_mode()
```

- The `change_mode` method is called whenever the user selects a new mode from the ComboBox.
- If the index is `0`, it means "Manual" mode, and the program will call `manual_mode()` to handle manual control.
- If the index is `1`, it means "Gesture" mode, and the program will call `gesture_mode()` to handle gesture control.

---

### 9. **Manual Mode**

```python
def manual_mode(self):
    # Here, manual controls for the LED will work
    pass
```

- This method is where you can implement manual controls, like turning the LED on or off when the user presses the buttons.
- We don’t add any extra logic here because manual control is already handled by the buttons (`button_led_off` and `button_led_on`).

---

### 10. **Gesture Mode**

```python
def gesture_mode(self):
    # In this mode, gestures will control the LED
    pass
```

- This method is where we can implement logic to control the LED based on gestures. In this case, the `gesture_mode()` method doesn't contain any extra logic because it's handled by the webcam feed in the `update_frame()` method.

---

### 11. **Turning the LED On and Off**

```python
def turn_led_on(self):
    self.arduino.write(b'1')  # Sends '1' to turn the LED ON
    print("LED ON")

def turn_led_off(self):
    self.arduino.write(b'0')  # Sends '0' to turn the LED OFF
    print("LED OFF")
```

- The `turn_led_on()` and `turn_led_off()` methods send the appropriate signal (`'1'` or `'0'`) to the Arduino to control the LED.
- When the "Turn LED ON" button is clicked, `turn_led_on()` sends `'1'` to the Arduino, and when the "Turn LED OFF" button is clicked, `turn_led_off()` sends `'0'`.

---

### 12. **Updating the Webcam Feed**

```python
def update_frame(self):
    success, frame = self.cap.read()
    if not success:
        return

    frame = cv2.flip(frame, 1)
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    result = self.hands.process(rgb_frame)

    if result.multi_hand_landmarks:
        for hand_landmarks in result.multi_hand_landmarks:
            self.mp_drawing.draw_landmarks(frame, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)

    h, w, ch = frame.shape
    bytes_per_line = ch * w
    q_image = QImage(frame.data, w, h, bytes_per_line, QImage.Format_BGR888)

    self.ui.webcam.setPixmap(QPixmap.fromImage(q_image))
```

- This method captures the frame from the webcam, processes it with MediaPipe to detect hands, and updates the GUI with the webcam feed.
- The webcam frame is flipped horizontally (`cv2.flip(frame, 1)`) and converted to RGB format (`cv2.cvtColor()`).
- If hands are detected, it draws the landmarks on the frame.
- Finally, the OpenCV frame is converted to a `QImage` and displayed in the `QLabel` widget (`self.ui.webcam`).

---

### 13. **Running the Application**

```python
if __name__ == "__main__":
    app = QApplication([])
    window = MainWindow()
    window.show()
    app.exec()
```

- This part starts the PySide6 application. `QApplication([])` initializes the app, and `window.show()` displays the main window.
- `app.exec()` starts the application loop, which keeps the app running and responsive.

---

### Conclusion

By following this lesson, you’ve integrated OpenCV, MediaPipe, and Arduino with PySide6 to create an interactive hand gesture control system! You can now switch between **Manual Mode** (where you control the LED with buttons) and **Gesture Mode** (where the LED is controlled using hand gestures).

---

[main.py](../python/integration/Lesson%2010/main.py)
```python
import cv2
import serial
import mediapipe as mp
from PySide6.QtCore import Qt, QTimer
from PySide6.QtWidgets import QApplication, QMainWindow, QLabel
from PySide6 import uic
from PySide6.QtGui import QImage, QPixmap

class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()

        # Set up the UI (generated from Qt Designer)
        self.ui = Ui_MainWindow()
        self.ui.setupUi(self)

        # Set up Arduino
        self.arduino = serial.Serial(port='/dev/cu.usbserial-1140', baudrate=9600, timeout=1)

        # Set up OpenCV and MediaPipe
        self.cap = cv2.VideoCapture(1)
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5)

        # Set up QTimer to update the webcam feed
        self.timer = QTimer(self)
        self.timer.timeout.connect(self.update_frame)
        self.timer.start(30)  # Update every 30ms

        # Connect signals to methods
        self.ui.comboBox_mode.currentIndexChanged.connect(self.change_mode)
        self.ui.button_led_off.clicked.connect(self.turn_led_off)
        self.ui.button_led_on.clicked.connect(self.turn_led_on)

    def change_mode(self, index):
        if index == 0:  # Manual Mode
            print("Manual Mode")
            self.manual_mode()
        else:  # Gesture Mode
            print("Gesture Mode")
            self.gesture_mode()

    def manual_mode(self):
        # Here, manual controls for the LED will work
        pass

    def gesture_mode(self):
        # In this mode, gestures will control the LED
        pass

    def turn_led_on(self):
        self.arduino.write(b'1')  # Sends '1' to turn the LED ON
        print("LED ON")

    def turn_led_off(self):
        self.arduino.write(b'0')  # Sends '0' to turn the LED OFF
        print("LED OFF")

    def update_frame(self):
        # Capture frame-by-frame from webcam
        success, frame = self.cap.read()
        if not success:
            return

        # Flip frame, convert to RGB for MediaPipe
        frame = cv2.flip(frame, 1)
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # Process the frame with MediaPipe
        result = self.hands.process(rgb_frame)

        if result.multi_hand_landmarks:
            for hand_landmarks in result.multi_hand_landmarks:
                self.mp_drawing.draw_landmarks(frame, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)

        # Convert OpenCV frame to QImage
        h, w, ch = frame.shape
        bytes_per_line = ch * w
        q_image = QImage(frame.data, w, h, bytes_per_line, QImage.Format_BGR888)

        # Update the Label to show the webcam frame
        self.ui.webcam.setPixmap(QPixmap.fromImage(q_image))

# Run the application
if __name__ == "__main__":
    app = QApplication([])
    window = MainWindow()
    window.show()
    app.exec()

```

